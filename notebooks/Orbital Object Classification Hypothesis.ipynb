{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import ttest_rel\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CCSDS_OMM_VERS                            COMMENT        CREATION_DATE  \\\n",
      "0               2  GENERATED VIA SPACE-TRACK.ORG API  2021-11-01T06:46:11   \n",
      "1               2  GENERATED VIA SPACE-TRACK.ORG API  2021-11-01T04:58:37   \n",
      "2               2  GENERATED VIA SPACE-TRACK.ORG API  2021-11-01T06:26:11   \n",
      "3               2  GENERATED VIA SPACE-TRACK.ORG API  2021-10-31T18:07:15   \n",
      "4               2  GENERATED VIA SPACE-TRACK.ORG API  2021-11-01T04:58:37   \n",
      "\n",
      "  ORIGINATOR      OBJECT_NAME   OBJECT_ID CENTER_NAME REF_FRAME TIME_SYSTEM  \\\n",
      "0    18 SPCS  ARIANE 42P+ DEB   1992-072J       EARTH      TEME         UTC   \n",
      "1    18 SPCS         SL-8 DEB   1979-028C       EARTH      TEME         UTC   \n",
      "2    18 SPCS           GSAT 1   2001-015A       EARTH      TEME         UTC   \n",
      "3    18 SPCS         CZ-4 DEB  1999-057MB       EARTH      TEME         UTC   \n",
      "4    18 SPCS         CZ-4 DEB  1999-057MC       EARTH      TEME         UTC   \n",
      "\n",
      "  MEAN_ELEMENT_THEORY  ... RCS_SIZE  COUNTRY_CODE  LAUNCH_DATE   SITE  \\\n",
      "0                SGP4  ...   MEDIUM            FR       1992.0  FRGUI   \n",
      "1                SGP4  ...    SMALL           CIS       1979.0  PKMTR   \n",
      "2                SGP4  ...    LARGE           IND       2001.0    SRI   \n",
      "3                SGP4  ...    SMALL           PRC       1999.0    TSC   \n",
      "4                SGP4  ...    SMALL           PRC       1999.0    TSC   \n",
      "\n",
      "   DECAY_DATE     FILE      GP_ID          TLE_LINE0  \\\n",
      "0         NaN  3195178  188614016  0 ARIANE 42P+ DEB   \n",
      "1         NaN  3194950  188593285         0 SL-8 DEB   \n",
      "2         NaN  3195026  188609573           0 GSAT 1   \n",
      "3         NaN  3194431  188556894         0 CZ-4 DEB   \n",
      "4         NaN  3194950  188592541         0 CZ-4 DEB   \n",
      "\n",
      "                                           TLE_LINE1  \\\n",
      "0  1 26741U 92072J   21304.94919376  .00000883  0...   \n",
      "1  1 26743U 79028C   21304.68908982  .00000079  0...   \n",
      "2  1 26745U 01015A   21305.22411368 -.00000165  0...   \n",
      "3  1 26754U 99057MB  21304.46625230  .00002265  0...   \n",
      "4  1 26755U 99057MC  21304.74081807  .00002610  0...   \n",
      "\n",
      "                                           TLE_LINE2  \n",
      "0  2 26741   7.7156  90.2410 6528926 243.1216  38...  \n",
      "1  2 26743  82.9193 299.1120 0030720 158.9093 201...  \n",
      "2  2 26745  12.1717  16.5368 0237386 250.1248 146...  \n",
      "3  2 26754  98.4781   8.7205 0060618  37.3771 323...  \n",
      "4  2 26755  98.4232 122.0724 0062255 345.1605  27...  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/eric_baldwin/ddiMain/capstone/ddi_capstone_2/data/space_decay.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CCSDS_OMM_VERS                            COMMENT        CREATION_DATE  \\\n",
      "0               2  GENERATED VIA SPACE-TRACK.ORG API  2021-11-01T06:46:11   \n",
      "1               2  GENERATED VIA SPACE-TRACK.ORG API  2021-11-01T04:58:37   \n",
      "2               2  GENERATED VIA SPACE-TRACK.ORG API  2021-11-01T06:26:11   \n",
      "3               2  GENERATED VIA SPACE-TRACK.ORG API  2021-10-31T18:07:15   \n",
      "4               2  GENERATED VIA SPACE-TRACK.ORG API  2021-11-01T04:58:37   \n",
      "\n",
      "  ORIGINATOR      OBJECT_NAME   OBJECT_ID CENTER_NAME REF_FRAME TIME_SYSTEM  \\\n",
      "0    18 SPCS  ARIANE 42P+ DEB   1992-072J       EARTH      TEME         UTC   \n",
      "1    18 SPCS         SL-8 DEB   1979-028C       EARTH      TEME         UTC   \n",
      "2    18 SPCS           GSAT 1   2001-015A       EARTH      TEME         UTC   \n",
      "3    18 SPCS         CZ-4 DEB  1999-057MB       EARTH      TEME         UTC   \n",
      "4    18 SPCS         CZ-4 DEB  1999-057MC       EARTH      TEME         UTC   \n",
      "\n",
      "  MEAN_ELEMENT_THEORY  ... OBJECT_TYPE  RCS_SIZE  COUNTRY_CODE  LAUNCH_DATE  \\\n",
      "0                SGP4  ...      DEBRIS    MEDIUM            FR       1992.0   \n",
      "1                SGP4  ...      DEBRIS     SMALL           CIS       1979.0   \n",
      "2                SGP4  ...     PAYLOAD     LARGE           IND       2001.0   \n",
      "3                SGP4  ...      DEBRIS     SMALL           PRC       1999.0   \n",
      "4                SGP4  ...      DEBRIS     SMALL           PRC       1999.0   \n",
      "\n",
      "    SITE     FILE      GP_ID          TLE_LINE0  \\\n",
      "0  FRGUI  3195178  188614016  0 ARIANE 42P+ DEB   \n",
      "1  PKMTR  3194950  188593285         0 SL-8 DEB   \n",
      "2    SRI  3195026  188609573           0 GSAT 1   \n",
      "3    TSC  3194431  188556894         0 CZ-4 DEB   \n",
      "4    TSC  3194950  188592541         0 CZ-4 DEB   \n",
      "\n",
      "                                           TLE_LINE1  \\\n",
      "0  1 26741U 92072J   21304.94919376  .00000883  0...   \n",
      "1  1 26743U 79028C   21304.68908982  .00000079  0...   \n",
      "2  1 26745U 01015A   21305.22411368 -.00000165  0...   \n",
      "3  1 26754U 99057MB  21304.46625230  .00002265  0...   \n",
      "4  1 26755U 99057MC  21304.74081807  .00002610  0...   \n",
      "\n",
      "                                           TLE_LINE2  \n",
      "0  2 26741   7.7156  90.2410 6528926 243.1216  38...  \n",
      "1  2 26743  82.9193 299.1120 0030720 158.9093 201...  \n",
      "2  2 26745  12.1717  16.5368 0237386 250.1248 146...  \n",
      "3  2 26754  98.4781   8.7205 0060618  37.3771 323...  \n",
      "4  2 26755  98.4232 122.0724 0062255 345.1605  27...  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(labels=['DECAY_DATE'], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename object type for better presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Debris' 'Payload' 'Rocket' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "df['OBJECT_TYPE'] = df['OBJECT_TYPE'].replace({'DEBRIS': 'Debris', 'PAYLOAD': 'Payload', 'TBA': 'Unknown', 'ROCKET BODY': 'Rocket'})\n",
    "print(df['OBJECT_TYPE'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill missing values for categorical columns with 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Debris\n",
      "1     Debris\n",
      "2    Payload\n",
      "3     Debris\n",
      "4     Debris\n",
      "Name: OBJECT_TYPE, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['COUNTRY_CODE'] = df['COUNTRY_CODE'].replace(to_replace={'TBD': 'Unknown', np.nan: 'Unknown'})\n",
    "df['RCS_SIZE'] = df['RCS_SIZE'].replace(to_replace={np.nan: 'Unknown'})\n",
    "print(df['OBJECT_TYPE'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PERIOD_HOURS and ALTITUDE_MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PERIOD_HOURS   ALTITUDE_MI\n",
      "0      8.214400   8883.110063\n",
      "1      1.744817    613.246709\n",
      "2     23.116400  21637.923148\n",
      "3      1.624267    400.164419\n",
      "4      1.629933    410.306520\n"
     ]
    }
   ],
   "source": [
    "df['PERIOD_HOURS'] = df['PERIOD'] / 60\n",
    "df['ALTITUDE_MI'] = (df['SEMIMAJOR_AXIS'] - 6371) * 0.6213\n",
    "print(df[['PERIOD_HOURS', 'ALTITUDE_MI']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert OBJECT_TYPE to binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9422\n",
      "1    4950\n",
      "Name: OBJECT_TYPE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['OBJECT_TYPE'] = df['OBJECT_TYPE'].apply(lambda x: 1 if x == 'Payload' else 0)\n",
    "print(df['OBJECT_TYPE'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   COUNTRY_CODE  RCS_SIZE\n",
      "0            29         1\n",
      "1            18         2\n",
      "2            36         0\n",
      "3            67         2\n",
      "4            67         2\n"
     ]
    }
   ],
   "source": [
    "le_country_code = LabelEncoder()\n",
    "df['COUNTRY_CODE'] = le_country_code.fit_transform(df['COUNTRY_CODE'])\n",
    "le_rcs_size = LabelEncoder()\n",
    "df['RCS_SIZE'] = le_rcs_size.fit_transform(df['RCS_SIZE'])\n",
    "print(df[['COUNTRY_CODE', 'RCS_SIZE']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill missing values for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCSDS_OMM_VERS       0\n",
      "MEAN_MOTION          0\n",
      "ECCENTRICITY         0\n",
      "INCLINATION          0\n",
      "RA_OF_ASC_NODE       0\n",
      "ARG_OF_PERICENTER    0\n",
      "MEAN_ANOMALY         0\n",
      "EPHEMERIS_TYPE       0\n",
      "NORAD_CAT_ID         0\n",
      "ELEMENT_SET_NO       0\n",
      "REV_AT_EPOCH         0\n",
      "BSTAR                0\n",
      "MEAN_MOTION_DOT      0\n",
      "MEAN_MOTION_DDOT     0\n",
      "SEMIMAJOR_AXIS       0\n",
      "PERIOD               0\n",
      "APOAPSIS             0\n",
      "PERIAPSIS            0\n",
      "OBJECT_TYPE          0\n",
      "RCS_SIZE             0\n",
      "COUNTRY_CODE         0\n",
      "LAUNCH_DATE          0\n",
      "FILE                 0\n",
      "GP_ID                0\n",
      "PERIOD_HOURS         0\n",
      "ALTITUDE_MI          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_cols] = imputer.fit_transform(df[numerical_cols])\n",
    "print(df[numerical_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INCLINATION  PERIOD_HOURS   ALTITUDE_MI  ECCENTRICITY  RA_OF_ASC_NODE  \\\n",
      "0       7.7156      8.214400   8883.110063      0.652893         90.2410   \n",
      "1      82.9193      1.744817    613.246709      0.003072        299.1120   \n",
      "2      12.1717     23.116400  21637.923148      0.023739         16.5368   \n",
      "3      98.4781      1.624267    400.164419      0.006062          8.7205   \n",
      "4      98.4232      1.629933    410.306520      0.006226        122.0724   \n",
      "\n",
      "   ARG_OF_PERICENTER  MEAN_ANOMALY  SEMIMAJOR_AXIS   APOAPSIS  PERIAPSIS  \n",
      "0           243.1216       38.7796       20668.618  27784.871    796.095  \n",
      "1           158.9093      201.3337        7358.038   1002.507    957.299  \n",
      "2           250.1248      146.2900       41197.852  35797.696  33841.738  \n",
      "3            37.3771      323.1632        7015.076    679.465    594.417  \n",
      "4           345.1605       27.6061        7031.400    697.039    609.491  \n"
     ]
    }
   ],
   "source": [
    "features = ['INCLINATION', 'PERIOD_HOURS', 'ALTITUDE_MI', 'ECCENTRICITY', 'RA_OF_ASC_NODE', 'ARG_OF_PERICENTER', 'MEAN_ANOMALY', 'SEMIMAJOR_AXIS', 'APOAPSIS', 'PERIAPSIS']\n",
    "X = df[features]\n",
    "y = df['OBJECT_TYPE']\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.24934758  0.60322852  1.04719468  3.22640749 -0.78921453  0.73851912\n",
      "  -1.38560132  1.04719468  1.69514994 -0.25166856]\n",
      " [ 0.2891097  -0.26614145 -0.34217606 -0.35306489  1.00038759 -0.06766244\n",
      "   0.09391195 -0.34217606 -0.36252374 -0.23137287]\n",
      " [-2.09893451  2.60573016  3.19005524 -0.23922497 -1.42071049  0.80556218\n",
      "  -0.40707747  3.19005524  2.31077069  3.90880033]\n",
      " [ 0.81428797 -0.28234072 -0.37797475 -0.33659587 -1.48768037 -1.23111503\n",
      "   1.20276348 -0.37797475 -0.38734287 -0.27705996]\n",
      " [ 0.81243486 -0.28157925 -0.37627084 -0.33569414 -0.5164838   1.71535836\n",
      "  -1.48729879 -0.37627084 -0.38599267 -0.27516213]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle class imbalance using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: [9422 4950]\n",
      "Resampled class distribution: [9422 9422]\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "print(\"Original class distribution:\", np.bincount(y))\n",
    "print(\"Resampled class distribution:\", np.bincount(y_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (13190, 10)\n",
      "Test set size: (5654, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Logistic Regression model & cross-validation to get accuracy scores for Logistic Regression without polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined Logistic Regression model.\n",
      "Logistic Regression scores without polynomial features: [0.70887036 0.71721001 0.71683093 0.70887036 0.70470053]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "\n",
    "logreg_scores = cross_val_score(logreg, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Logistic Regression scores without polynomial features:\", logreg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Added polynomial features & split data into training and test sets for polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size with polynomial features: (13190, 65)\n",
      "Test set size with polynomial features: (5654, 65)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_poly_resampled, y_poly_resampled = smote.fit_resample(X_poly, y)\n",
    "\n",
    "X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(X_poly_resampled, y_poly_resampled, test_size=0.3, random_state=42)\n",
    "print(\"Training set size with polynomial features:\", X_poly_train.shape)\n",
    "print(\"Test set size with polynomial features:\", X_poly_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation to get accuracy scores for Logistic Regression with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression scores with polynomial features: [0.8146323  0.80022745 0.8085671  0.79378317 0.78809704]\n"
     ]
    }
   ],
   "source": [
    "logreg_poly_scores = cross_val_score(logreg, X_poly_train, y_poly_train, cv=5, scoring='accuracy')\n",
    "print(\"Logistic Regression scores with polynomial features:\", logreg_poly_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -20.8863499474633, p-value: 3.105225148998835e-05\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_value = ttest_rel(logreg_scores, logreg_poly_scores)\n",
    "print(f\"t-statistic: {t_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis - there is a significant difference between the two configurations\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis - there is a significant difference between the two configurations\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis - no significant difference between the two configurations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
